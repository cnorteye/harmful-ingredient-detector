{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "0",
   "metadata": {},
   "source": [
    "# Basic Ingredient Extraction from Product Labels\n",
    "\n",
    "## 1. Introduction\n",
    "- Goal: Try extracting ingredients from cosmetic or food product labels using OCR (EasyOCR).\n",
    "- Purpose: Simulate real-world data extraction to enhance dataset robustness.\n",
    "\n",
    "## 2. Install EasyOCR\n",
    "(pip install easyocr)\n",
    "\n",
    "## 3. OCR Extraction\n",
    "- Run EasyOCR on 1-2 sample images.\n",
    "- Save extracted text to .txt files.\n",
    "\n",
    "## 4. Sample Outputs\n",
    "- View and analyze OCR results.\n",
    "\n",
    "## 5. Future Work\n",
    "- Suggest improvements like better OCR, post-processing, etc.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "\n",
    "# Set working directory to project root\n",
    "os.chdir(r\"C:\\Users\\User\\Documents\\cs599_deepLearning\\harmful-ingredient-detector\")\n",
    "print(\"âœ… Now in:\", os.getcwd())\n",
    "\n",
    "# Add root to Python path\n",
    "sys.path.append(os.getcwd())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2",
   "metadata": {},
   "source": [
    "### Preprocessing the Image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3",
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from pathlib import Path\n",
    "\n",
    "# --- Preprocessing function ---\n",
    "def preprocess_image(filepath):\n",
    "    img = cv2.imread(str(filepath))\n",
    "    gray = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)\n",
    "\n",
    "    # Denoising\n",
    "    denoised = cv2.fastNlMeansDenoising(gray, h=30)\n",
    "\n",
    "    # Contrast Enhancement (CLAHE)\n",
    "    clahe = cv2.createCLAHE(clipLimit=0.5, tileGridSize=(8, 8))\n",
    "    enhanced = clahe.apply(denoised)\n",
    "\n",
    "    # Binarization\n",
    "    _, thresh = cv2.threshold(enhanced, 0, 255, cv2.THRESH_BINARY + cv2.THRESH_OTSU)\n",
    "\n",
    "    return img, thresh\n",
    "\n",
    "# --- Save Preprocessed Only ---\n",
    "def save_processed_images(image_folder, processed_folder):\n",
    "    image_paths = list(Path(image_folder).glob('*.jpg'))\n",
    "    processed_folder = Path(processed_folder)\n",
    "    processed_folder.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "    for img_path in image_paths:\n",
    "        original_img, processed_img = preprocess_image(img_path)\n",
    "        save_path = processed_folder / (img_path.stem + '.png')\n",
    "        cv2.imwrite(str(save_path), processed_img)\n",
    "        print(f\"Saved preprocessed image: {save_path}\")\n",
    "\n",
    "# --- Save Before/After Comparison ---\n",
    "def save_before_after_comparison(image_folder, save_folder):\n",
    "    image_paths = list(Path(image_folder).glob('*.jpg'))\n",
    "    save_folder = Path(save_folder)\n",
    "    save_folder.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "    for img_path in image_paths:\n",
    "        original_img, processed_img = preprocess_image(img_path)\n",
    "\n",
    "        fig, axes = plt.subplots(1, 2, figsize=(12, 6))\n",
    "        fig.suptitle(f\"{img_path.name}\", fontsize=16)\n",
    "\n",
    "        axes[0].imshow(cv2.cvtColor(original_img, cv2.COLOR_BGR2RGB))\n",
    "        axes[0].set_title('Original')\n",
    "        axes[0].axis('off')\n",
    "\n",
    "        axes[1].imshow(processed_img, cmap='gray')\n",
    "        axes[1].set_title('Preprocessed')\n",
    "        axes[1].axis('off')\n",
    "\n",
    "        save_path = save_folder / f\"{img_path.stem}_comparison.png\"\n",
    "        plt.savefig(str(save_path), bbox_inches='tight')\n",
    "        plt.close()\n",
    "\n",
    "        print(f\"Saved comparison: {save_path}\")\n",
    "\n",
    "# --- Example Usage ---\n",
    "image_folder = 'images/beauty_ingredients'\n",
    "processed_folder = 'images/beauty_ingredients_preprocessed'\n",
    "save_folder = 'images/comparison_plots'\n",
    "\n",
    "save_processed_images(image_folder, processed_folder)\n",
    "save_before_after_comparison(image_folder, save_folder)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4",
   "metadata": {},
   "source": [
    "### Step 1: OCR Extraction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import easyocr\n",
    "\n",
    "# Create output folder\n",
    "ocr_output_dir = \"./images/ocr_outputs\"\n",
    "os.makedirs(ocr_output_dir, exist_ok=True)\n",
    "\n",
    "# Re-initialize EasyOCR Reader\n",
    "reader = easyocr.Reader(['en'], gpu=False)\n",
    "\n",
    "# Folder with preprocessed images\n",
    "preprocessed_dir = \"./images/beauty_ingredients_preprocessed\"\n",
    "image_paths = [os.path.join(preprocessed_dir, img) for img in os.listdir(preprocessed_dir) if img.endswith(\".png\")]\n",
    "\n",
    "for img_path in image_paths:\n",
    "    img_filename = os.path.basename(img_path)\n",
    "    output_txt_path = os.path.join(ocr_output_dir, img_filename.replace(\".png\", \".txt\"))\n",
    "    \n",
    "    print(f\"\\nExtracting text from {img_filename}...\")\n",
    "    results = reader.readtext(img_path)\n",
    "    \n",
    "    extracted_text = []\n",
    "    for (bbox, text, confidence) in results:\n",
    "        # Keep text only if OCR confidence is decent\n",
    "        if confidence > 0.4:  # You can lower/raise this threshold if needed\n",
    "            extracted_text.append(text.strip())\n",
    "\n",
    "    # Save to .txt file\n",
    "    with open(output_txt_path, \"w\", encoding=\"utf-8\") as f:\n",
    "        f.write(\"\\n\".join(extracted_text))\n",
    "    \n",
    "    print(f\"Saved extracted text to {output_txt_path}\")\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6",
   "metadata": {},
   "source": [
    "### Step 2: Ingredient Cleaning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7",
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "from textblob import TextBlob\n",
    "from pathlib import Path\n",
    "\n",
    "def clean_extracted_text(text_list):\n",
    "    cleaned_ingredients = []\n",
    "    for text in text_list:\n",
    "        text = text.lower().strip()\n",
    "        text = re.sub(r'[^a-z0-9\\s\\(\\)\\-\\/,]', '', text)\n",
    "\n",
    "        if any(word in text for word in ['directions', 'apply', 'store', 'cool', 'website', 'massage', 'usa', 'net weight', 'social', 'ingredient']):\n",
    "            continue\n",
    "        if len(text) < 3:\n",
    "            continue\n",
    "\n",
    "        blob = TextBlob(text)\n",
    "        corrected = str(blob.correct())\n",
    "\n",
    "        corrected = re.sub(r'\\s+', ' ', corrected).strip()\n",
    "        cleaned_ingredients.append(corrected)\n",
    "        print(f\"âœ… Cleaned line: {corrected}\")\n",
    "    return cleaned_ingredients\n",
    "\n",
    "def save_cleaned_ocr_files(ocr_input_folder, cleaned_output_folder):\n",
    "    print(\"inside save cleaned\")\n",
    "    ocr_input_folder = Path(ocr_input_folder)\n",
    "    cleaned_output_folder = Path(cleaned_output_folder)\n",
    "    cleaned_output_folder.mkdir(parents=True, exist_ok=True)\n",
    "    print(\"before loop\")\n",
    "\n",
    "    for ocr_file in sorted(ocr_input_folder.glob(\"*.txt\")):\n",
    "        print(f\"ðŸ“„ Processing {ocr_file.name}...\")\n",
    "\n",
    "        with open(ocr_file, \"r\", encoding=\"utf-8\") as f:\n",
    "            lines = f.readlines()\n",
    "\n",
    "        cleaned_lines = clean_extracted_text(lines)\n",
    "\n",
    "        cleaned_file_path = cleaned_output_folder / ocr_file.name\n",
    "        with open(cleaned_file_path, \"w\", encoding=\"utf-8\") as f:\n",
    "            for line in cleaned_lines:\n",
    "                f.write(line + \"\\n\")\n",
    "\n",
    "        print(f\"âœ… Saved cleaned file: {cleaned_file_path}\")\n",
    "\n",
    "# âœ… Correct folder name\n",
    "ocr_input_folder = Path.cwd() / \"./images/ocr_outputs\"    # <-- No \"s\"\n",
    "cleaned_output_folder = Path.cwd() / \"./images/ocr_output_cleaned\"\n",
    "\n",
    "save_cleaned_ocr_files(ocr_input_folder, cleaned_output_folder)\n",
    "\n",
    "print(\"Finished cleaning.\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8",
   "metadata": {},
   "source": [
    "### Normalization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from rapidfuzz import process, fuzz\n",
    "from pathlib import Path\n",
    "\n",
    "# 1. Load COSING\n",
    "cosing_file = Path(\"images/COSING_Ingredients-Fragrance Inventory_v3.csv\")\n",
    "cosing_df = pd.read_csv(cosing_file)\n",
    "\n",
    "# Extract Column B (INCI names)\n",
    "inci_names = cosing_df.iloc[:, 1].dropna().str.lower().tolist()\n",
    "\n",
    "# 2. Normalization Function\n",
    "def normalize_ingredient(text, reference_list, threshold=85):\n",
    "    text = text.lower().strip()\n",
    "\n",
    "    if text in reference_list:\n",
    "        return text, 100  # Perfect match\n",
    "\n",
    "    match, score, _ = process.extractOne(text, reference_list, scorer=fuzz.ratio)\n",
    "    if score >= threshold:\n",
    "        return match, score\n",
    "    else:\n",
    "        return text, score\n",
    "\n",
    "# 3. Normalize and Log\n",
    "def normalize_ocr_outputs(cleaned_folder, normalized_folder, log_csv_path):\n",
    "    cleaned_folder = Path(cleaned_folder)\n",
    "    normalized_folder = Path(normalized_folder)\n",
    "    normalized_folder.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "    summary_records = []  # for summary CSV\n",
    "\n",
    "    for cleaned_file in sorted(cleaned_folder.glob(\"*.txt\")):\n",
    "        with open(cleaned_file, \"r\", encoding=\"utf-8\") as f:\n",
    "            lines = f.read().splitlines()\n",
    "\n",
    "        normalized_lines = []\n",
    "        for line in lines:\n",
    "            normalized_text, score = normalize_ingredient(line, inci_names)\n",
    "            normalized_lines.append(normalized_text)\n",
    "\n",
    "            summary_records.append({\n",
    "                \"file\": cleaned_file.name,\n",
    "                \"ocr_extracted\": line,\n",
    "                \"normalized_inci\": normalized_text,\n",
    "                \"similarity_score\": score\n",
    "            })\n",
    "\n",
    "        normalized_file_path = normalized_folder / cleaned_file.name\n",
    "        with open(normalized_file_path, \"w\", encoding=\"utf-8\") as f:\n",
    "            for line in normalized_lines:\n",
    "                f.write(line + \"\\n\")\n",
    "\n",
    "        print(f\"âœ… Normalized {cleaned_file.name}\")\n",
    "\n",
    "    # Save full summary CSV\n",
    "    summary_df = pd.DataFrame(summary_records)\n",
    "    summary_df.to_csv(log_csv_path, index=False)\n",
    "    print(f\"ðŸ“„ Full summary saved at {log_csv_path}\")\n",
    "\n",
    "# 4. Execute\n",
    "cleaned_folder = \"./images/ocr_output_cleaned\"\n",
    "normalized_folder = \"./images/ocr_outputs_normalized\"\n",
    "log_csv_path = \"ingredient_normalization_summary.csv\"\n",
    "\n",
    "normalize_ocr_outputs(cleaned_folder, normalized_folder, log_csv_path)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "10",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(Path.cwd())"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
